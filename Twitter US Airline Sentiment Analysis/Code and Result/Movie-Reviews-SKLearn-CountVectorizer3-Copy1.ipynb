{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import movie_reviews\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk import word_tokenize \n",
    "import io\n",
    "import os\n",
    "import re\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from google.colab import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:\\\\Users\\\\hp\\\\Coding Ninjas\\\\Lectures\\\\Lect 16(NLP)\\\\Projects\\\\Twitter US Airline Sentiment Analysis\\\\Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@SouthwestAir I am scheduled for the morning, 2 days after the fact, yes..not sure why my evening flight was the only one Cancelled Flightled'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data=pd.read_csv('training_data.csv')\n",
    "training_data[\"text\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"@AmericanAir In car gng to DFW. Pulled over 1hr ago - very icy roads. On-hold with AA since 1hr. Can't reach arpt for AA2450. Wat 2 do?\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_data=pd.read_csv(\"test_data.csv\")\n",
    "testing_data[\"text\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=training_data[\"text\"]\n",
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3660, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest=testing_data[\"text\"]\n",
    "xtest=np.array(xtest)\n",
    "xtest=xtest.reshape(len(xtest),1)\n",
    "xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10980, 1), (10980, 1))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=training_data['airline_sentiment']\n",
    "x=np.array(x)\n",
    "y=np.array(y)\n",
    "x=x.reshape(len(x),1)\n",
    "y=y.reshape(len(y),1)\n",
    "x.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10980, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=np.append(x,y,axis=1)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3660, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=xtest\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The End\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(['@',\n",
       "   'SouthwestAir',\n",
       "   'I',\n",
       "   'am',\n",
       "   'scheduled',\n",
       "   'for',\n",
       "   'the',\n",
       "   'morning',\n",
       "   ',',\n",
       "   '2',\n",
       "   'days',\n",
       "   'after',\n",
       "   'the',\n",
       "   'fact',\n",
       "   ',',\n",
       "   'yes..not',\n",
       "   'sure',\n",
       "   'why',\n",
       "   'my',\n",
       "   'evening',\n",
       "   'flight',\n",
       "   'was',\n",
       "   'the',\n",
       "   'only',\n",
       "   'one',\n",
       "   'Cancelled',\n",
       "   'Flightled'],\n",
       "  'negative')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = []\n",
    "c=0\n",
    "for text,category in train:\n",
    "    c+=1\n",
    "    documents.append((word_tokenize(text), category))\n",
    "print(\"The End\")\n",
    "documents[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The End\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['[',\n",
       "  '``',\n",
       "  '@',\n",
       "  'AmericanAir',\n",
       "  'In',\n",
       "  'car',\n",
       "  'gng',\n",
       "  'to',\n",
       "  'DFW',\n",
       "  '.',\n",
       "  'Pulled',\n",
       "  'over',\n",
       "  '1hr',\n",
       "  'ago',\n",
       "  '-',\n",
       "  'very',\n",
       "  'icy',\n",
       "  'roads',\n",
       "  '.',\n",
       "  'On-hold',\n",
       "  'with',\n",
       "  'AA',\n",
       "  'since',\n",
       "  '1hr',\n",
       "  '.',\n",
       "  'Ca',\n",
       "  \"n't\",\n",
       "  'reach',\n",
       "  'arpt',\n",
       "  'for',\n",
       "  'AA2450',\n",
       "  '.',\n",
       "  'Wat',\n",
       "  '2',\n",
       "  'do',\n",
       "  '?',\n",
       "  \"''\",\n",
       "  ']'],\n",
       " ['[',\n",
       "  \"'\",\n",
       "  '@',\n",
       "  'AmericanAir',\n",
       "  'after',\n",
       "  'all',\n",
       "  ',',\n",
       "  'the',\n",
       "  'plane',\n",
       "  'didn',\n",
       "  'â€™',\n",
       "  't',\n",
       "  'land',\n",
       "  'in',\n",
       "  'identical',\n",
       "  'or',\n",
       "  'worse',\n",
       "  ')',\n",
       "  'conditions',\n",
       "  'at',\n",
       "  'GRK',\n",
       "  'according',\n",
       "  'to',\n",
       "  'METARs',\n",
       "  '.',\n",
       "  \"'\",\n",
       "  ']'],\n",
       " ['[',\n",
       "  '``',\n",
       "  '@',\n",
       "  'SouthwestAir',\n",
       "  'ca',\n",
       "  \"n't\",\n",
       "  'believe',\n",
       "  'how',\n",
       "  'many',\n",
       "  'paying',\n",
       "  'customers',\n",
       "  'you',\n",
       "  'left',\n",
       "  'high',\n",
       "  'and',\n",
       "  'dry',\n",
       "  'with',\n",
       "  'no',\n",
       "  'reason',\n",
       "  'for',\n",
       "  'flight',\n",
       "  'Cancelled',\n",
       "  'Flightlations',\n",
       "  'Monday',\n",
       "  'out',\n",
       "  'of',\n",
       "  'BDL',\n",
       "  '!',\n",
       "  'Wow',\n",
       "  '.',\n",
       "  \"''\",\n",
       "  ']'],\n",
       " ['[',\n",
       "  \"'\",\n",
       "  '@',\n",
       "  'USAirways',\n",
       "  'I',\n",
       "  'can',\n",
       "  'legitimately',\n",
       "  'say',\n",
       "  'that',\n",
       "  'I',\n",
       "  'would',\n",
       "  'have',\n",
       "  'rather',\n",
       "  'driven',\n",
       "  'cross',\n",
       "  'country',\n",
       "  'than',\n",
       "  'flown',\n",
       "  'on',\n",
       "  'US',\n",
       "  'Airways',\n",
       "  '.',\n",
       "  \"'\",\n",
       "  ']'],\n",
       " ['[',\n",
       "  \"'\",\n",
       "  '@',\n",
       "  'AmericanAir',\n",
       "  'still',\n",
       "  'no',\n",
       "  'response',\n",
       "  'from',\n",
       "  'AA',\n",
       "  '.',\n",
       "  'great',\n",
       "  'job',\n",
       "  'guys',\n",
       "  '!',\n",
       "  \"'\",\n",
       "  ']']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_documents = []\n",
    "c=0\n",
    "for text in test:\n",
    "    c+=1\n",
    "    test_documents.append(word_tokenize(str(text)))\n",
    "print(\"The End\")\n",
    "test_documents[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['@',\n",
       "   'AmericanAir',\n",
       "   'when',\n",
       "   'do',\n",
       "   'you',\n",
       "   'anticipate',\n",
       "   'decisions',\n",
       "   'for',\n",
       "   'Cancelled',\n",
       "   'Flightlations',\n",
       "   'at',\n",
       "   'DFW',\n",
       "   'tomorrow',\n",
       "   'morning',\n",
       "   '?',\n",
       "   'Need',\n",
       "   'to',\n",
       "   'rearrange',\n",
       "   'hotel',\n",
       "   'reservations',\n",
       "   ',',\n",
       "   'etc',\n",
       "   '.',\n",
       "   'ASAP',\n",
       "   '!'],\n",
       "  'negative'),\n",
       " (['@',\n",
       "   'united',\n",
       "   'I',\n",
       "   'bet',\n",
       "   '@',\n",
       "   'SouthwestAir',\n",
       "   'does',\n",
       "   \"n't\",\n",
       "   'turn',\n",
       "   'a',\n",
       "   'thirty',\n",
       "   'minute',\n",
       "   'delay',\n",
       "   'on',\n",
       "   'an',\n",
       "   'original',\n",
       "   'flight',\n",
       "   'into',\n",
       "   'a',\n",
       "   '7+',\n",
       "   'hour',\n",
       "   'delayed',\n",
       "   'arrive',\n",
       "   'time'],\n",
       "  'negative'),\n",
       " (['@',\n",
       "   'SouthwestAir',\n",
       "   'can',\n",
       "   'you',\n",
       "   'please',\n",
       "   'DM',\n",
       "   'me',\n",
       "   'who',\n",
       "   'I',\n",
       "   'can',\n",
       "   'speak',\n",
       "   'with',\n",
       "   'regarding',\n",
       "   'my',\n",
       "   'receipts',\n",
       "   'and',\n",
       "   'who',\n",
       "   'I',\n",
       "   'can',\n",
       "   'email',\n",
       "   'a',\n",
       "   'presidential',\n",
       "   'level',\n",
       "   'complaint'],\n",
       "  'negative'),\n",
       " (['@',\n",
       "   'JetBlue',\n",
       "   'Oh',\n",
       "   'I',\n",
       "   'will',\n",
       "   '.',\n",
       "   '#',\n",
       "   'Disney',\n",
       "   'bound',\n",
       "   '.',\n",
       "   '#',\n",
       "   'workhard',\n",
       "   '#',\n",
       "   'playsoon'],\n",
       "  'neutral'),\n",
       " (['@',\n",
       "   'USAirways',\n",
       "   'It',\n",
       "   \"'s\",\n",
       "   'not',\n",
       "   'double',\n",
       "   'booked',\n",
       "   '.',\n",
       "   'I',\n",
       "   'spoke',\n",
       "   'with',\n",
       "   'CS',\n",
       "   'and',\n",
       "   'we',\n",
       "   \"'ve\",\n",
       "   'got',\n",
       "   'a',\n",
       "   'plan',\n",
       "   'to',\n",
       "   'fix',\n",
       "   'this',\n",
       "   '.',\n",
       "   'It',\n",
       "   \"'s\",\n",
       "   'still',\n",
       "   'an',\n",
       "   'amateur',\n",
       "   'mistake',\n",
       "   'that',\n",
       "   'should',\n",
       "   'never',\n",
       "   'happen',\n",
       "   '.'],\n",
       "  'negative')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.shuffle(documents)\n",
    "documents[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "def get_simple_pos(tag):\n",
    "    \n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('better', 'RBR')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import pos_tag\n",
    "w = \"better\"\n",
    "pos_tag([w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "stops = set(stopwords.words('english'))\n",
    "punctuations = list(string.punctuation)\n",
    "stops.update(punctuations)\n",
    "#stops, string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_review(words):\n",
    "    output_words = []\n",
    "    regex = re.compile('[a-zA-Z0-9_-]+$')\n",
    "    for w in words:\n",
    "        if w.lower() not in stops and len(w)>2 and not w.isnumeric() and re.match(regex,w):\n",
    "            pos = pos_tag([w])\n",
    "            clean_word = lemmatizer.lemmatize(w, pos = get_simple_pos(pos[0][1]))\n",
    "            output_words.append(clean_word.lower())\n",
    "    return output_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [(clean_review(document), category) for document, category in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_documents = [clean_review(document) for document in test_documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_documents = documents\n",
    "testing_documents = test_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 2, 1],\n",
       "        [1, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = {\"the sky sky is blue\", \"the sun is bright\"}\n",
    "count_vec = CountVectorizer(max_features = 3)\n",
    "a = count_vec.fit_transform(train_set)\n",
    "a.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['is', 'sky', 'the']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vec.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ad is'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [\"ad\", \"is\"]\n",
    "\" \".join(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [category for document, category in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining All features in each tuple for Train Data\n",
    "\n",
    "text_documents = [\" \".join(document) for document, category in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining All features in each tuple for Test Data\n",
    "\n",
    "test_text_documents = [\" \".join(document) for document in test_documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(text_documents, categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 1, 0, 0],\n",
       "        [0, 0, 0, ..., 1, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 1, 0, 1],\n",
       "        [1, 0, 1, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vec = CountVectorizer(max_features = 20, ngram_range=(1,2))\n",
    "x_train_features = count_vec.fit_transform(x_train)\n",
    "x_train_features.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8235, 20)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['americanair',\n",
       " 'amp',\n",
       " 'bag',\n",
       " 'call',\n",
       " 'cancelled',\n",
       " 'customer',\n",
       " 'flight',\n",
       " 'get',\n",
       " 'help',\n",
       " 'hour',\n",
       " 'http',\n",
       " 'jetblue',\n",
       " 'plane',\n",
       " 'service',\n",
       " 'southwestair',\n",
       " 'thanks',\n",
       " 'time',\n",
       " 'united',\n",
       " 'usairways',\n",
       " 'wait']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vec.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_features = count_vec.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2745x20 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 5927 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain=x_train_features\n",
    "ytrain=y_train\n",
    "xtest=x_test_features\n",
    "ytest=y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=5, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC(C=5)\n",
    "svc.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.score(xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from nltk import NaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classfier = NaiveBayesClassifier.train(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#naive=classfier.classify_many(ytest)\n",
    "#naive=np.array(naive)\n",
    "#nltk.classify.accuracy(classfier, ytest)\n",
    "#os.chdir(\"C:\\\\Users\\\\hp\\\\Desktop\")\n",
    "#np.savetxt(\"naive1.csv\",naive, fmt='%s',encoding=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
